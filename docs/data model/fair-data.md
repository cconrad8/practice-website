---
sidebar_position: 1
---

# A Model for FAIR Science

## Why?

The [FAIR guiding principles for scientific data management and stewardship](https://www.go-fair.org/fair-principles/) stipulate that data should be **F**indable, **A**ccessible, **I**nteroperable, and **R**eusable. 
This helps create a scientific ecosystem promoting transparency, reuse, and collaboration to accelerate scientific discoveries. 
And beginning in 2023, the [NIH Data Management and Sharing Policy](https://sharing.nih.gov/data-management-and-sharing-policy/about-data-management-and-sharing-policies/data-management-and-sharing-policy-overview) requires data sharing for NIH-supported studies. 
The Gray Foundation DCC helps consortium teams meet or exceed NIH data sharing policies in the pursuit of better science. 

This benefits consortium teams in several ways:
1. More collaborative and productive work in the *present* consortium effort, because teams can better find and use the data they are sharing with each other.
2. More competitive grant proposals (especially Team Science-type proposals) in *future* efforts because teams can demonstrate a good track record of data sharing: 
> In 2010, a group of scientists called for consideration of all products of research grants rather than just peer-reviewed publications, including sharing of raw data and self-published results on the web and through social media ... The new movement already has had some effects, as NSF has changed the language of required biosketches to include products such as datasets, software, patents, and copyrights. ([Funding and Evaluation of Team Science](https://www.ncbi.nlm.nih.gov/books/NBK310379/))   
3. More impact and citations from other researchers who might wish to reuse the data, protocols, etc.

Sharing and linking of data and other resources requires collection of metadata to describe them and make them more e.g. findable and reusable. 
A data model defines what metadata is preferentially collected.

## Development Process

The DCC develops the model using existing standards while also consulting the contributing teams for specialized data. 
A broader development process, when the model affects the wider consortium, involves a Request for Comments (RFC) process. 
For example, please see the public [first RFC document](https://coda.io/@gf-dcc/rfc-1-mcdm) (archived/closed) that has helped determine the current core model.
Continued development, if necessary, can involve additional RFCs. 

### Data Model Source

The data model source is versioned [here](https://github.com/gf-dcc/data-model). 

## Capturing Metadata Through Templates

Data are captured through spreadsheet templates, available as either Google Sheets or Excel (in cases where contributors can't access Google products due to institutional policies). 
See the next sections for examples.
